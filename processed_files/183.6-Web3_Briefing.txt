AR and VR refer to two emerging human-computer interface categories which are both designed around interaction models that involve multiple sensory modalities (immersive visual display, as well as auditory, haptic, and proprioceptive forms of both input and output). Specifically, Augmented Reality refers to any interface which uses real-world visual information (as live digital video on a display, or as seen by the naked eye through a transparent display) which is then “augmented” by a digital overlay that is coordinated with the environment in real-time. Often AR involves the insertion of 3D and 2D digital objects & image-filters into the environment that is being displayed using motion tracking software systems (these systems usually include cameras, accelerometers, and possibly other forms of spatial sensing like LIDAR), but as previously stated they can also include auditory and haptic feedback as part of the real-time augmentation. On the other hand, Virtual Reality is underpinned by an entirely computer generated visual environment displayed through a VR headset which uses specialized optics to present an image that covers the user’s entire field of view. Virtual Reality also involves data captured by cameras and accelerometers, most often to translate real-world motion (of head position/orientation, hand motion, and the surrounding environment) into virtual motion manifested by changes in the computer generated environment. AR and VR are overlapping interface typologies, insofar as both use the motion and orientation of the user to continuously update the visual display in order to simulate a coherence between environment (which is either entirely or partly computer generated) and occupant (which is always based on a real user, and then projected virtually as a point-of-view [virtual camera position] or avatar). Since their earliest iterations, both AR and VR have been embraced and pioneered by many developers in the video game industry, however, many other applications have been proposed and prototyped in fields and industries both in and beyond entertainment, including: design, construction, telecommunication, logistics, manufacturing, commerce, film & TV, visual art, education, social networking, navigation, war, and even scientific research.
	The Metaverse, a portmanteau of “meta” and “universe”. AR and VR interfaces are integral to the speculative transformation of the world wide web into a new paradigm known as “the metaverse”. The term is originally from a science fiction novel from the early 90’s (Snow Crash by Neil Stephenson, 1992) which described a near future instantiation of the internet that was entirely mediated by virtual reality, this led to a unification of all parts and ‘locations’ of the world wide web into one semi-continuous virtual geography that was made to be spatial and traversable. This metaverse environment, being a simulated plane of reality complete with real-time communication between virtual instantiations of users (avatars), could host virtual economic activity that was entirely supported by the resources and demand contained within the virtual world. The “virtual world platform” Second Life was one of the earliest realizations of this concept, but it predated any even remotely viable (commercially) form of Virtual Reality and was therefore only ever mediated through a traditional web browser on a flat display. Recent advances in commercial VR technology have reinvigorated the interest in this kind of web development.

Metaverse applications and platforms have not yet found complete integration with the space of Web3/DeFi applications and platforms, however the potential synergy is palpable to many involved in these industries, where some would argue that AR/VR platform development on the web will necessarily be built on top blockchain technology and DApps. In the future, the following categories of service apps will definitely be connected to blockchains in some way, usually in the form